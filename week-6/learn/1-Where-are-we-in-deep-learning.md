# Where are we in Deep Learning? 

Traditional Aritificial Intelligence research started in the 1950s as a proof a concept. By the 1980s the classical machine learning period had started. The classical machine learning period created algorithms such as the ones covered so far in this module among others.

The classical ML algorithms we have covered so far are as follows

- Linear Regression (Supervised)
- Logistic Regression (Supervised)
- Decision Trees (Supervised)
- Support Vector Machines (SVM, Supervised)
- K-Means Clustering (UnSupervised)
- Principal Component Analysis (PCA)
- Non-Negative Matrix Factorization (NMF)

These traditional methods are often referred to as 'shallow learning'.
This is because their computing architectures are relatively simple and do not scale well. 

This has prompted a new era of AI, known as Deep Learnining to deal with the ever expanding size of Data in the modern era. 
The prior methods performnces saturate quickly even when providing more data to these massive datasets. 

Starting in 2010, Deep Learning models became more widely used in the industry. 
Deep Learning Models are considerable more complicated that their predecessors. 
As a result, the can continue to improve on their performance given more data. 

Convolutional Neural Networks (CNNs) are a type of Deep Learning model and are used for data aquisition from image data. 
CNNs are the topic of this weeks content. 

## Brief History of AI: 

The evolution of AI has taken several stages:
 
- Beginning with the electronic brain (1943) 
- The Perceptron (1957)
- ADALINE (1960) 
- XOR problem (1969) 
- Multilayered perceptron and backpropagation (1986) 
- SVM (1995)
- Deep neural networks (2006).




