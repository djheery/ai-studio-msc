{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "226d910e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Train Accuracy  Validation Accuracy  Prediction Accuracy  Train Loss  \\\n",
      "Model 1              90                   88                   87         0.1   \n",
      "Model 2              85                   82                   81         0.2   \n",
      "\n",
      "         Validation Loss  \n",
      "Model 1             0.09  \n",
      "Model 2             0.18  \n",
      "         Train Accuracy  Validation Accuracy  Prediction Accuracy  Train Loss  \\\n",
      "Model 1              90                   88                   87         0.1   \n",
      "Model 2              85                   82                   81         0.2   \n",
      "\n",
      "         Validation Loss  \n",
      "Model 1             0.09  \n",
      "Model 2             0.18  \n",
      "x_train shape:  (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Create a new dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Add columns for the metrics you want to compare\n",
    "df['train_acc'] = [90, 85] # example values for model 1 and model 2\n",
    "df['val_accuracy'] = [88, 82] # example values for model 1 and model 2\n",
    "df['prediction_accuracy'] = [87, 81] # example values for model 1 and model 2\n",
    "df['train_loss'] = [0.1, 0.2] # example values for model 1 and model 2\n",
    "df['val_loss'] = [0.09, 0.18] # example values for model 1 and model 2\n",
    "\n",
    "# Add titles to the columns and rows\n",
    "df.columns = ['Train Accuracy', 'Validation Accuracy', 'Prediction Accuracy', 'Train Loss', 'Validation Loss']\n",
    "df.index = ['Model 1', 'Model 2']\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)\n",
    "\n",
    "# Display the dataframe\n",
    "print(df)\n",
    "\n",
    "print('x_train shape: ', x_train.shape)\n",
    "\n",
    "# Output = x_train shape: (5000, 32, 32, 3)\n",
    "# This means: \n",
    "# - 5000 images\n",
    "# - 32x32 (height/width) dimensional images\n",
    "# - 3 pixels in depth (corresponding to RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10caf253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape:  (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('y_train shape: ', y_train.shape)\n",
    "\n",
    "# Output: y_train shape: (5000, 1)\n",
    "\n",
    "# That means there is one number (corresponding to the label) for each of the 5000 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71e49ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 59  62  63]\n",
      "  [ 43  46  45]\n",
      "  [ 50  48  43]\n",
      "  ...\n",
      "  [158 132 108]\n",
      "  [152 125 102]\n",
      "  [148 124 103]]\n",
      "\n",
      " [[ 16  20  20]\n",
      "  [  0   0   0]\n",
      "  [ 18   8   0]\n",
      "  ...\n",
      "  [123  88  55]\n",
      "  [119  83  50]\n",
      "  [122  87  57]]\n",
      "\n",
      " [[ 25  24  21]\n",
      "  [ 16   7   0]\n",
      "  [ 49  27   8]\n",
      "  ...\n",
      "  [118  84  50]\n",
      "  [120  84  50]\n",
      "  [109  73  42]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[208 170  96]\n",
      "  [201 153  34]\n",
      "  [198 161  26]\n",
      "  ...\n",
      "  [160 133  70]\n",
      "  [ 56  31   7]\n",
      "  [ 53  34  20]]\n",
      "\n",
      " [[180 139  96]\n",
      "  [173 123  42]\n",
      "  [186 144  30]\n",
      "  ...\n",
      "  [184 148  94]\n",
      "  [ 97  62  34]\n",
      "  [ 83  53  34]]\n",
      "\n",
      " [[177 144 116]\n",
      "  [168 129  94]\n",
      "  [179 142  87]\n",
      "  ...\n",
      "  [216 184 140]\n",
      "  [151 118  84]\n",
      "  [123  92  72]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "\n",
    "# The output is the pixel numbers within the image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386895ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %matplotlibb inline tells the notebbook that you wish for the image to display within the image. \n",
    "# img.plt.imshow is a function that displays the numbered pixel values x_train[0] to the actual image it represents. \n",
    "\n",
    "# The code for showing the image:\n",
    "img = plt.imshow(x_train[0])\n",
    "\n",
    "# The image is pixilated because it's been enlarged as its a 32x32 image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f2a6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label is:  [6]\n"
     ]
    }
   ],
   "source": [
    "# Working out what the label of the above image is: \n",
    "\n",
    "print('The label is: ', y_train[0])\n",
    "\n",
    "# You can repeat the process above to see the different labels and images for the data\n",
    "# In the lab there is a table that shows that 6 = a frog \n",
    "\n",
    "# The numbering is as follows: \n",
    "\n",
    "# 0 - Airplane \n",
    "# 1 - Automobile \n",
    "# 2 - bird\n",
    "# 3 - cat\n",
    "# 4 - deer\n",
    "# 5 - dog\n",
    "# 6 - frog \n",
    "# 7 - horse \n",
    "# 8 - ship \n",
    "# 9 - truck "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19fa9773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the labels to be ordered in some way.\n",
    "# Lecture example: \n",
    "\n",
    "# If the network can't decide if the given image is a truck or airplane should we take \n",
    "# halfway point and predict it as a dog? Short answer, NO. \n",
    "\n",
    "# What we need is the probability of each of the 10 different classes. For that, we need 10 output neurons \n",
    "# in our network. One for each label \n",
    "\n",
    "# To do this, we convert the label into a set of 10 numbers where each number\n",
    "# represents if the image bbelongs to a certain class or not.\n",
    "# If an image belongs to the first class, the first number of this set will be a 1 and all other numbers set\n",
    "# to 0.\n",
    "\n",
    "# This process is called a \"One Hot Encoding\"\n",
    "# There is an example of the conversion table in the lab task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17205e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one hot label is:  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# To do one-hot encoding on each label the code is as follows: \n",
    "y_train_one_hot = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Testing the one-hot encoding:\n",
    "# It is expected that the 6th item will be a 1 and the rest 0 as it is an image of a frog \n",
    "print('The one hot label is: ', y_train_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f01e8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.23137255 0.24313726 0.24705882]\n",
      "  [0.16862746 0.18039216 0.1764706 ]\n",
      "  [0.19607843 0.1882353  0.16862746]\n",
      "  ...\n",
      "  [0.61960787 0.5176471  0.42352942]\n",
      "  [0.59607846 0.49019608 0.4       ]\n",
      "  [0.5803922  0.4862745  0.40392157]]\n",
      "\n",
      " [[0.0627451  0.07843138 0.07843138]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.07058824 0.03137255 0.        ]\n",
      "  ...\n",
      "  [0.48235294 0.34509805 0.21568628]\n",
      "  [0.46666667 0.3254902  0.19607843]\n",
      "  [0.47843137 0.34117648 0.22352941]]\n",
      "\n",
      " [[0.09803922 0.09411765 0.08235294]\n",
      "  [0.0627451  0.02745098 0.        ]\n",
      "  [0.19215687 0.10588235 0.03137255]\n",
      "  ...\n",
      "  [0.4627451  0.32941177 0.19607843]\n",
      "  [0.47058824 0.32941177 0.19607843]\n",
      "  [0.42745098 0.28627452 0.16470589]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.8156863  0.6666667  0.3764706 ]\n",
      "  [0.7882353  0.6        0.13333334]\n",
      "  [0.7764706  0.6313726  0.10196079]\n",
      "  ...\n",
      "  [0.627451   0.52156866 0.27450982]\n",
      "  [0.21960784 0.12156863 0.02745098]\n",
      "  [0.20784314 0.13333334 0.07843138]]\n",
      "\n",
      " [[0.7058824  0.54509807 0.3764706 ]\n",
      "  [0.6784314  0.48235294 0.16470589]\n",
      "  [0.7294118  0.5647059  0.11764706]\n",
      "  ...\n",
      "  [0.72156864 0.5803922  0.36862746]\n",
      "  [0.38039216 0.24313726 0.13333334]\n",
      "  [0.3254902  0.20784314 0.13333334]]\n",
      "\n",
      " [[0.69411767 0.5647059  0.45490196]\n",
      "  [0.65882355 0.5058824  0.36862746]\n",
      "  [0.7019608  0.5568628  0.34117648]\n",
      "  ...\n",
      "  [0.84705883 0.72156864 0.54901963]\n",
      "  [0.5921569  0.4627451  0.32941177]\n",
      "  [0.48235294 0.36078432 0.28235295]]]\n"
     ]
    }
   ],
   "source": [
    "# Processing our image (x)\n",
    "# A common step we do is to allow the values between 0 and 1, which will aid in the training of our NN\n",
    "# Since our pixel values already take the values between 0 and 255 we simply need to dived by 255\n",
    "\n",
    "# In practice, what we do is convert the type to 'float32'\n",
    "# float32 is a datatype that can store values with decimal points\n",
    "# We then divide each cell by 255.  \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255 \n",
    "\n",
    "## The areay produced by first training image with processing applied: \n",
    "# The array values have been normalized between 0 and 1 which is computationally easier to handle\n",
    "print(x_train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4e8c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\\nBUILDING AND TRAINING OUR CNN\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "BUILDING AND TRAINING OUR CNN\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "# The last layer of a CNN is a softmax layer \n",
    "# A softmax layer transforms the output of the previous layer into probability distributions for \n",
    "# classification purposes.\n",
    "\n",
    "# For now, we will zero-pad our layer such that the output width and height will be the same \n",
    "# as the input width and height, we'll have to pad with a border of 1. \n",
    "# We will be applying 'same' padding for convolutional layers\n",
    "\n",
    "# Lastly we will use ReLU activation for all our layers except "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da91a88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 595,498\n",
      "Trainable params: 595,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-06 12:00:50.328955: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-06 12:00:50.329425: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# Parms for model.add()\n",
    "# filter=3x3, stride_size=1 (in both dimensions), depth=32, padding=same, activation = relu\n",
    "# The first layer needs an input size, subsequent layers do not due as they can infer this \n",
    "# from the first layer\n",
    "\n",
    "# Params for Max Pooling \n",
    "# Pool size - the dimensions of the pooling dividers (2x2) in this case \n",
    "# stride - Default is 2 and that is what we will use thus we do not need to specify \n",
    "\n",
    "# Dropout layer is the prevent overfitting \n",
    "# The dropout layer randomly sets th\n",
    "\n",
    "# Calling an empty Sequential Model\n",
    "model = Sequential()\n",
    "# Layer 1 (Convultional Layer)`\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "# Layer 2 (Convultional Layer)\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "# Layer 3 (Max Pooling)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Layer 4 (Dropout layer)\n",
    "model.add(Dropout(0.25))\n",
    "# Layer 5 - 8\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Flatten the output to change the output from the previous layer \n",
    "# From a cube like structure to neurons in 1 row so it can be input to 1 layer \n",
    "model.add(Flatten())\n",
    "# Dense Layer\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# Dropout \n",
    "model.add(Dropout(0.5))\n",
    "# Fully connected layer with 10 neurons as probbability distrubutions and a softax activation function \n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Print the architecture \n",
    "model.summary()\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91e06dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1250/1250 [==============================] - 95s 76ms/step - loss: 1.5586 - accuracy: 0.4270 - val_loss: 1.2089 - val_accuracy: 0.5778\n",
      "Epoch 2/40\n",
      "1250/1250 [==============================] - 93s 75ms/step - loss: 1.1084 - accuracy: 0.6052 - val_loss: 0.9682 - val_accuracy: 0.6573\n",
      "Epoch 3/40\n",
      "1250/1250 [==============================] - 100s 80ms/step - loss: 0.9384 - accuracy: 0.6676 - val_loss: 0.8658 - val_accuracy: 0.7025\n",
      "Epoch 4/40\n",
      "1250/1250 [==============================] - 104s 83ms/step - loss: 0.8313 - accuracy: 0.7113 - val_loss: 0.8236 - val_accuracy: 0.7137\n",
      "Epoch 5/40\n",
      "1250/1250 [==============================] - 109s 87ms/step - loss: 0.7633 - accuracy: 0.7319 - val_loss: 0.7338 - val_accuracy: 0.7496\n",
      "Epoch 6/40\n",
      "1250/1250 [==============================] - 107s 86ms/step - loss: 0.7058 - accuracy: 0.7526 - val_loss: 0.7262 - val_accuracy: 0.7507\n",
      "Epoch 7/40\n",
      "1250/1250 [==============================] - 101s 81ms/step - loss: 0.6602 - accuracy: 0.7670 - val_loss: 0.6782 - val_accuracy: 0.7674\n",
      "Epoch 8/40\n",
      "1250/1250 [==============================] - 109s 87ms/step - loss: 0.6216 - accuracy: 0.7815 - val_loss: 0.6967 - val_accuracy: 0.7648\n",
      "Epoch 9/40\n",
      "1250/1250 [==============================] - 92s 73ms/step - loss: 0.5919 - accuracy: 0.7902 - val_loss: 0.6827 - val_accuracy: 0.7660\n",
      "Epoch 10/40\n",
      "1250/1250 [==============================] - 119s 95ms/step - loss: 0.5563 - accuracy: 0.8031 - val_loss: 0.6989 - val_accuracy: 0.7668\n",
      "Epoch 11/40\n",
      "1250/1250 [==============================] - 92s 73ms/step - loss: 0.5283 - accuracy: 0.8148 - val_loss: 0.6856 - val_accuracy: 0.7737\n",
      "Epoch 12/40\n",
      "1250/1250 [==============================] - 103s 82ms/step - loss: 0.5101 - accuracy: 0.8194 - val_loss: 0.6911 - val_accuracy: 0.7734\n",
      "Epoch 13/40\n",
      "1250/1250 [==============================] - 108s 86ms/step - loss: 0.4830 - accuracy: 0.8274 - val_loss: 0.7324 - val_accuracy: 0.7761\n",
      "Epoch 14/40\n",
      "1250/1250 [==============================] - 87s 70ms/step - loss: 0.4682 - accuracy: 0.8332 - val_loss: 0.6971 - val_accuracy: 0.7714\n",
      "Epoch 15/40\n",
      "1250/1250 [==============================] - 87s 70ms/step - loss: 0.4474 - accuracy: 0.8395 - val_loss: 0.7156 - val_accuracy: 0.7708\n",
      "Epoch 16/40\n",
      "1250/1250 [==============================] - 102s 81ms/step - loss: 0.4395 - accuracy: 0.8446 - val_loss: 0.7105 - val_accuracy: 0.7782\n",
      "Epoch 17/40\n",
      "1250/1250 [==============================] - 98s 79ms/step - loss: 0.4215 - accuracy: 0.8505 - val_loss: 0.7590 - val_accuracy: 0.7736\n",
      "Epoch 18/40\n",
      "1250/1250 [==============================] - 108s 87ms/step - loss: 0.4138 - accuracy: 0.8553 - val_loss: 0.7428 - val_accuracy: 0.7729\n",
      "Epoch 19/40\n",
      "1250/1250 [==============================] - 106s 84ms/step - loss: 0.4014 - accuracy: 0.8590 - val_loss: 0.7841 - val_accuracy: 0.7769\n",
      "Epoch 20/40\n",
      "1250/1250 [==============================] - 110s 88ms/step - loss: 0.3922 - accuracy: 0.8616 - val_loss: 0.7253 - val_accuracy: 0.7844\n",
      "Epoch 21/40\n",
      "1250/1250 [==============================] - 105s 84ms/step - loss: 0.3805 - accuracy: 0.8635 - val_loss: 0.7453 - val_accuracy: 0.7822\n",
      "Epoch 22/40\n",
      "1250/1250 [==============================] - 99s 79ms/step - loss: 0.3724 - accuracy: 0.8687 - val_loss: 0.7407 - val_accuracy: 0.7854\n",
      "Epoch 23/40\n",
      "1250/1250 [==============================] - 104s 83ms/step - loss: 0.3658 - accuracy: 0.8709 - val_loss: 0.7735 - val_accuracy: 0.7803\n",
      "Epoch 24/40\n",
      "1250/1250 [==============================] - 103s 82ms/step - loss: 0.3540 - accuracy: 0.8758 - val_loss: 0.7774 - val_accuracy: 0.7782\n",
      "Epoch 25/40\n",
      "1250/1250 [==============================] - 106s 85ms/step - loss: 0.3554 - accuracy: 0.8747 - val_loss: 0.7694 - val_accuracy: 0.7822\n",
      "Epoch 26/40\n",
      "1250/1250 [==============================] - 100s 80ms/step - loss: 0.3457 - accuracy: 0.8776 - val_loss: 0.7686 - val_accuracy: 0.7781\n",
      "Epoch 27/40\n",
      "1250/1250 [==============================] - 94s 75ms/step - loss: 0.3437 - accuracy: 0.8791 - val_loss: 0.7737 - val_accuracy: 0.7854\n",
      "Epoch 28/40\n",
      "1250/1250 [==============================] - 109s 87ms/step - loss: 0.3292 - accuracy: 0.8849 - val_loss: 0.8776 - val_accuracy: 0.7656\n",
      "Epoch 29/40\n",
      "1250/1250 [==============================] - 108s 86ms/step - loss: 0.3353 - accuracy: 0.8839 - val_loss: 0.7756 - val_accuracy: 0.7804\n",
      "Epoch 30/40\n",
      "1250/1250 [==============================] - 104s 83ms/step - loss: 0.3261 - accuracy: 0.8854 - val_loss: 0.9064 - val_accuracy: 0.7746\n",
      "Epoch 31/40\n",
      "1250/1250 [==============================] - 106s 85ms/step - loss: 0.3166 - accuracy: 0.8877 - val_loss: 0.7981 - val_accuracy: 0.7821\n",
      "Epoch 32/40\n",
      "1250/1250 [==============================] - 108s 87ms/step - loss: 0.3161 - accuracy: 0.8891 - val_loss: 0.8241 - val_accuracy: 0.7795\n",
      "Epoch 33/40\n",
      "  94/1250 [=>............................] - ETA: 1:37 - loss: 0.2938 - accuracy: 0.8969"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2866/288665321.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \"\"\"\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Studio/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Studio/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Studio/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Studio/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Studio/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Studio/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Studio/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Studio/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Studio/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Copile the model made above: \n",
    "\n",
    "# - Categorical Cross entropy is applicable for a classification problem with many classes \n",
    "# - Optimizer is adam - Adam is simply a type of stochastic gradient descent (with modifications)\n",
    "# - metrics - we want to compute the \"accuracy of our model\"\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\"\"\"\"\n",
    "Train our model with a batch size of 32\n",
    "30 epochs\n",
    "Validation test split of 0.2. This is a change to using validation_data and spliting our dataset manually as we did \n",
    "at the start\n",
    "\"\"\"\n",
    "\n",
    "hist = model.fit(x_train, y_train_one_hot, verbose=1, batch_size=32, epochs=40, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "890018fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2866/1806675954.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualization of the Training Data \n",
    "\n",
    "# Loss\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', \"Validation\"], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a1ec846",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2866/3884862893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plotting the Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "# Plotting the Accuracy\n",
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(['Train', \"Validation\"], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c7f00dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.6835 - accuracy: 0.7661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7660999894142151"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test_one_hot)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13100c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209568f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
